#==========================================
# LLM Passthrough Service Alerting Rules
# Dashboard: LLM Passthrough Service - Unified Observability
# Dashboard UID: llm-passthrough-unified-observability
#==========================================

#==========================================
# Reusable YAML Anchors
#==========================================

# Reusable label definitions
x-default-labels: &x-default-labels
  team: "llm_passthrough_platform"
  pillar: "flex"
  value_stream: "ai"
  sub_stream: "ai_foundational_experiences"
  service: "service-large-language-model"
  contact_point: "llm_passthrough_prod_pagerduty"

x-default-rule-settings-ukg-pro: &x-default-rule-settings-ukg-pro
  data_source: UKG Pro
  alert_group: FleX - AI - LLM Passthrough
  interval: 5m

x-default-rule-settings-ukg-dev: &x-default-rule-settings-ukg-dev
  data_source: UKG Dev
  alert_group: FleX - AI - LLM Passthrough
  interval: 5m

x-default-rule-settings-grafanacloud-ukg-prom: &x-default-rule-settings-grafanacloud-ukg-prom
  data_source: grafanacloud-ukg-prom
  data_source_type: prometheus
  folder: Flex
  alert_group: FleX - AI - LLM Passthrough
  interval: 5m


grafanacloud_rules:

  #==========================================
  # Layer 0 - Synthetic / External Monitoring
  #==========================================

  # LLM Passthrough Metrics Endpoint Monitoring
  # Monitors Prometheus metrics scraping endpoint availability for LLM service
  # Triggers when metrics endpoint is not reachable indicating monitoring blind spots
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P1 : AI - LLM Passthrough: L0: Metrics endpoint not scraped successfully"
    expr: |
      up{
        namespace=~"ds-prod|ds-salesa|ds-salesb",
        instance=~".*large-language-model.*",
        datacenter!="us-east4"
      } < 1
    for: 30m
    labels:
      <<: *x-default-labels
      severity: critical
      observability_layer: 0
      observability_layer_metric: service_availability_checks
    annotations:
      description: "L0: LLM Passthrough metrics endpoint not scraped successfully for instance: {{ $labels.instance }} in namespace: {{ $labels.namespace }} and datacenter: {{ $labels.datacenter }}."
      summary: "L0: LLM Passthrough metrics endpoint not scraped successfully job: {{ $labels.job }} instance: {{ $labels.instance }}"
      SOPs: "TBD - Create SOP for LLM Passthrough metrics scraping issues"
      __dashboardUid__: llm-passthrough-unified-observability
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'


  #==========================================
  # Layer 1 - Infrastructure / OS Level
  #==========================================

  # LLM Passthrough Deployment Replica Monitoring
  # Monitors Kubernetes deployment health by comparing available replicas to specified replicas
  # Triggers when any LLM service has fewer than 50% of running pods than specified
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P1 : AI - LLM Passthrough : L1: Deployment replicas below spec on Prod"
    expr: |
      (
        sum by (deployment, datacenter, namespace) (
          kube_deployment_status_replicas_available{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            deployment=~"service-large-language-model.*"
          }
        )
        /
        sum by (deployment, datacenter, namespace) (
          kube_deployment_spec_replicas{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            deployment=~"service-large-language-model.*"
          }
        )
      ) < 0.5
    for: 20m
    labels:
      <<: *x-default-labels
      severity: critical
      observability_layer: 1
      observability_layer_metric: os_availability_checks
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough deployment replica issues"
      summary: "LLM Passthrough deployment replicas below specification"
      description: "L1: LLM Passthrough deployment: {{ $labels.deployment }} in namespace: {{ $labels.namespace }} datacenter: {{ $labels.datacenter }} has replicas below 50% of its replica specification."
      __dashboardUid__: llm-passthrough-unified-observability
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # LLM Passthrough Container CPU Usage Monitoring
  # Monitors container CPU usage across LLM service in production environment
  # Triggers when CPU usage exceeds threshold for sustained period
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P3 : AI - LLM Passthrough : L1: High Container CPU Usage in Prod"
    expr: |
      avg by (service_name, datacenter, namespace) (
        label_replace(
          rate(container_cpu_usage_seconds_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            container=~"service-large-language-model.*"
          }[60m]),
          "service_name",
          "$1",
          "pod",
          "^(.*?)-[^-]+-[^-]+$"
        )
      ) * 1000 >= 75
    for: 30m
    labels:
      <<: *x-default-labels
      severity: warning
      observability_layer: 1
      observability_layer_metric: os_resource_usage_checks
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough high CPU usage"
      summary: "L1: LLM Passthrough container CPU usage exceeds threshold"
      description: "L1: LLM Passthrough container has CPU usage of {{ $value }} millicores which exceeds 75 millicores threshold."
      __dashboardUid__: llm-passthrough-unified-observability
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # LLM Passthrough Container Memory Usage Monitoring
  # Monitors container memory usage across LLM service in production environment
  # Triggers when memory usage exceeds 95% of allocated memory resources
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P3 : AI - LLM Passthrough : L1: High Container Memory Usage in Prod"
    expr: |
      100 * (
        max by (container, datacenter, namespace) (
          container_memory_working_set_bytes{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            container=~"service-large-language-model.*"
          }
        )
        /
        max by (container, datacenter, namespace) (
          kube_pod_container_resource_limits{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            resource="memory",
            container=~"service-large-language-model.*"
          }
        )
      ) >= 95
    for: 30m
    labels:
      <<: *x-default-labels
      severity: warning
      observability_layer: 1
      observability_layer_metric: os_resource_usage_checks
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough high memory usage"
      summary: "LLM Passthrough container memory usage exceeds threshold"
      description: "LLM Passthrough container has memory usage of {{ $value }}% which exceeds 95% of allocated memory resources."
      __dashboardUid__: llm-passthrough-unified-observability
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # LLM Passthrough Container Restart Monitoring
  # Monitors container restarts across LLM service in production environment
  # Triggers when containers experience frequent restarts indicating instability
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P1 : AI - LLM Passthrough : L1: High Container Restarts in Prod"
    expr: |
      sum by (datacenter, cluster, namespace, pod, container) (
        increase(kube_pod_container_status_restarts_total{
          namespace=~"ds-prod|ds-salesa|ds-salesb",
          pod=~"service-large-language-model.*",
          container!~"(envoy-trox|istio-proxy)",
          pod!="shell"
        }[15m])
      ) >= 4
    for: 15m
    labels:
      <<: *x-default-labels
      severity: critical
      observability_layer: 1
      observability_layer_metric: os_error_rate
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough container restart issues"
      summary: "LLM Passthrough container experiencing frequent restarts"
      description: "LLM Passthrough container {{ $labels.pod }}/{{ $labels.container }} has restarted {{ $value }} times in the last 15 minutes."
      __dashboardUid__: llm-passthrough-unified-observability
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'


  #==========================================
  # Layer 3 - Application Level
  #==========================================

  # CRITICAL ALERT: High Error Rate (5xx)
  # Per technical requirements: 5xx error rate > 15% for 15 minutes
  # Polling done 3 times in 5 min interval (15 min total)
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P1 : AI - LLM Passthrough : L3: High 5xx Error Rate - CRITICAL"
    # Query calculates 5xx error rate as percentage of total requests
    # Uses 5-minute rate windows for stability
    # Triggers when error rate exceeds 15% threshold
    expr: |
      (
        sum by (namespace, datacenter) (
          rate(http_request_count_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model",
            http_status=~"5.."
          }[5m])
        )
        /
        sum by (namespace, datacenter) (
          rate(http_request_count_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
      ) * 100 > 15
    for: 15m
    labels:
      <<: *x-default-labels
      severity: critical
      observability_layer: 3
      observability_layer_metric: application_error_rate
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough high error rate"
      summary: "CRITICAL: LLM Passthrough 5xx error rate exceeds 15% threshold"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has 5xx error rate of {{ $value | printf \"%.2f\" }}% which exceeds 15% threshold for the last 15 minutes."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 401
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # Combined 4xx/5xx Error Rate Alert
  # Monitors overall application health including client errors
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P2 : AI - LLM Passthrough : L3: High Combined Error Rate"
    expr: |
      (
        sum by (namespace, datacenter) (
          rate(http_request_count_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model",
            http_status=~"[45].."
          }[5m])
        )
        /
        sum by (namespace, datacenter) (
          rate(http_request_count_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
      ) * 100 > 20
    for: 15m
    labels:
      <<: *x-default-labels
      severity: warning
      observability_layer: 3
      observability_layer_metric: application_error_rate
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough high combined error rate"
      summary: "WARNING: LLM Passthrough combined error rate (4xx+5xx) exceeds 20% threshold"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has combined error rate of {{ $value | printf \"%.2f\" }}% which exceeds 20% threshold."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 4
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # HTTP Success Rate Alert
  # Monitors overall success rate dropping below acceptable threshold
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P2 : AI - LLM Passthrough : L3: HTTP Success Rate Below 85%"
    expr: |
      (
        sum by (namespace, datacenter) (
          rate(http_request_count_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model",
            http_status=~"2.."
          }[5m])
        )
        /
        sum by (namespace, datacenter) (
          rate(http_request_count_total{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
      ) * 100 < 85
    for: 15m
    labels:
      <<: *x-default-labels
      severity: warning
      observability_layer: 3
      observability_layer_metric: application_success_rate
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough low success rate"
      summary: "WARNING: LLM Passthrough HTTP success rate below 85%"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has HTTP success rate of {{ $value | printf \"%.2f\" }}% which is below 85% threshold."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 1
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'


  #==========================================
  # Layer 4 - Latency / Performance
  #==========================================

  # WARNING ALERT: Response Time Degradation (P95 Latency)
  # Per technical requirements: P95 > 10 seconds for 15 minutes
  # Polling done 3 times in 5 min interval (15 min total)
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P2 : AI - LLM Passthrough : L4: Response Time Degradation - P95 Latency High"
    # Query calculates P95 latency using histogram_quantile
    # Uses sum by (le) for proper histogram aggregation in Mimir
    # Triggers when P95 exceeds 10 seconds threshold
    expr: |
      histogram_quantile(0.95,
        sum by (le, namespace, datacenter) (
          rate(request_incoming_duration_seconds_bucket{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
      ) > 10
    for: 15m
    labels:
      <<: *x-default-labels
      severity: warning
      observability_layer: 4
      observability_layer_metric: application_latency
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough response time degradation"
      summary: "WARNING: LLM Passthrough P95 latency exceeds 10 second threshold"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has P95 latency of {{ $value | printf \"%.2f\" }} seconds which exceeds 10 second threshold for the last 15 minutes."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 402
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # P99 Latency Alert - Critical threshold
  # Monitors worst-case response times
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P2 : AI - LLM Passthrough : L4: P99 Latency Extremely High"
    expr: |
      histogram_quantile(0.99,
        sum by (le, namespace, datacenter) (
          rate(request_incoming_duration_seconds_bucket{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
      ) > 30
    for: 15m
    labels:
      <<: *x-default-labels
      severity: warning
      observability_layer: 4
      observability_layer_metric: application_latency
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough extreme latency"
      summary: "WARNING: LLM Passthrough P99 latency exceeds 30 second threshold"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has P99 latency of {{ $value | printf \"%.2f\" }} seconds which exceeds 30 second threshold."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 13
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'

  # Average Latency Alert
  # Monitors overall average response time
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P3 : AI - LLM Passthrough : L4: Average Latency High"
    expr: |
      (
        sum by (namespace, datacenter) (
          rate(request_incoming_duration_seconds_sum{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
        /
        sum by (namespace, datacenter) (
          rate(request_incoming_duration_seconds_count{
            namespace=~"ds-prod|ds-salesa|ds-salesb",
            name="service-large-language-model"
          }[5m])
        )
      ) > 15
    for: 15m
    labels:
      <<: *x-default-labels
      severity: info
      observability_layer: 4
      observability_layer_metric: application_latency
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough high average latency"
      summary: "INFO: LLM Passthrough average latency exceeds 15 second threshold"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has average latency of {{ $value | printf \"%.2f\" }} seconds which exceeds 15 second threshold."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 11
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'


  #==========================================
  # Layer 5 - Traffic / Capacity
  #==========================================

  # Low Traffic Alert - Potential issue indicator
  # Monitors for unexpected drop in traffic which could indicate upstream issues
  - <<: *x-default-rule-settings-ukg-pro
    alert: "P3 : AI - LLM Passthrough : L5: Unexpectedly Low Traffic"
    expr: |
      sum by (namespace, datacenter) (
        rate(http_request_count_total{
          namespace=~"ds-prod",
          name="service-large-language-model"
        }[30m])
      ) < 0.01
      and
      hour() >= 8 and hour() <= 20
      and
      day_of_week() >= 1 and day_of_week() <= 5
    for: 30m
    labels:
      <<: *x-default-labels
      severity: info
      observability_layer: 5
      observability_layer_metric: traffic_volume
    annotations:
      SOPs: "TBD - Create SOP for LLM Passthrough low traffic investigation"
      summary: "INFO: LLM Passthrough experiencing unexpectedly low traffic during business hours"
      description: "LLM Passthrough service in namespace: {{ $labels.namespace }}, datacenter: {{ $labels.datacenter }} has very low request rate during business hours. This may indicate upstream issues or routing problems."
      __dashboardUid__: llm-passthrough-unified-observability
      __panelId__: 8
      dashboard_url: 'https://ukg.grafana.net/d/llm-passthrough-unified-observability?orgId=1&from=now-12h&to=now&timezone=browser&var-datasource=fdfh4wr47u5tsb&var-namespace=ds-prod&var-dc=$__all'


#==========================================
# Contact Points Configuration
#==========================================

grafanacloud_contactpoints:
  - name: llm_passthrough_prod_pagerduty
    route_type: pagerduty
    routing_key: "TBD - Add PagerDuty routing key"  # Update with actual PagerDuty integration key
    group_by: ['alertname', 'severity', 'namespace', 'datacenter']
    send_resolve: true

  - name: llm_passthrough_slack
    route_type: slack
    webhook_url: "TBD - Add Slack webhook URL"  # Update with actual Slack webhook
    channel: "#llm-passthrough-alerts"
    group_by: ['alertname', 'severity']
    send_resolve: true


#==========================================
# Notification Policies (Route Configuration)
#==========================================

grafanacloud_notification_policies:
  - receiver: llm_passthrough_prod_pagerduty
    matchers:
      - alertname =~ "P1.*LLM Passthrough.*"
      - severity = critical
    continue: true
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 4h

  - receiver: llm_passthrough_slack
    matchers:
      - alertname =~ ".*LLM Passthrough.*"
    continue: false
    group_wait: 1m
    group_interval: 10m
    repeat_interval: 1h
